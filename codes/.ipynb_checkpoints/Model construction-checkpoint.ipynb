{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv, os\n",
    "from glob import glob\n",
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "#load the data\n",
    "PATH = \"/Users/leeo/Desktop/KI2/7.master_thesis/1.data/14.feature_label_intact_5min/label_fe/combine_fe/training_data_undersample_binary.csv\"\n",
    "df = pd.read_csv(PATH, sep=\",\", header=0,\n",
    "                       parse_dates=[0], index_col=0)\n",
    "#add coefficient of variance\n",
    "df[\"cv\"] = df[\"std\"]/df[\"mean\"]\n",
    "df[\"cv.1\"] = df[\"std.1\"]/df[\"mean.1\"]\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-2:] + cols[:-2]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and testing dataseet\n",
    "#df = shuffle(df,random_state=42)\n",
    "X=df[df.columns[:-2]]  # Features\n",
    "y=df[df.columns[-2]]  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # 70% training and 30% test\n",
    "#df.iloc[X_test.index][\"label\"].value_counts()\n",
    "#df.iloc[X_train.index][\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[5731  460]\n",
      " [ 933 2182]]\n",
      "Accuracy 0.8503116269073716\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.93      0.89      6191\n",
      "         1.0       0.83      0.70      0.76      3115\n",
      "\n",
      "    accuracy                           0.85      9306\n",
      "   macro avg       0.84      0.81      0.82      9306\n",
      "weighted avg       0.85      0.85      0.85      9306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create a RF Classifier\n",
    "clf=RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#apply the model\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, Precisiono and recall\n",
    "print(\"Confusion matrix:\\n\",metrics.confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Classification_report:\\n\",metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "#Train the model using the entire training sets \n",
    "#clf.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/p3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:25:50] 21711x16 matrix with 347376 entries loaded from dtrain.svm\n",
      "[16:25:50] 9306x16 matrix with 148896 entries loaded from dtest.svm\n"
     ]
    }
   ],
   "source": [
    "# use DMatrix for xgbosot\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "\n",
    "# use svmlight file for xgboost\n",
    "dump_svmlight_file(X_train, y_train, 'dtrain.svm', zero_based=True)\n",
    "dump_svmlight_file(X_test, y_test, 'dtest.svm', zero_based=True)\n",
    "dtrain_svm = xgb.DMatrix('dtrain.svm')\n",
    "dtest_svm = xgb.DMatrix('dtest.svm')\n",
    "\n",
    "# set xgboost params\n",
    "param = {\n",
    "    'max_depth': 6,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this datset\n",
    "num_round = 10  # the number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[5587  604]\n",
      " [1312 1803]]\n",
      "Accuracy 0.7941113260262196\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.90      0.85      6191\n",
      "         1.0       0.75      0.58      0.65      3115\n",
      "\n",
      "    accuracy                           0.79      9306\n",
      "   macro avg       0.78      0.74      0.75      9306\n",
      "weighted avg       0.79      0.79      0.79      9306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and testing - numpy matrices\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = bst.predict(dtest)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "#model evaluation: Model Accuracy, Precisiono and recall\n",
    "print(\"Confusion matrix:\\n\",metrics.confusion_matrix(y_test, best_preds))\n",
    "print(\"Accuracy\",metrics.accuracy_score(y_test, best_preds))\n",
    "print(\"Classification_report:\\n\",metrics.classification_report(y_test, best_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "* The running time is approximately 2h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='rbf')\n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "#apply the model\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "# Model Accuracy, Precisiono and recall\n",
    "print(\"Confusion matrix:\\n\",metrics.confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Classification_report:\\n\",metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[2314  862   43]\n",
      " [ 955 1453   39]\n",
      " [ 243  416  109]]\n",
      "Accuracy 0.6024246192104445\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.72      0.69      3219\n",
      "         1.0       0.53      0.59      0.56      2447\n",
      "         2.0       0.57      0.14      0.23       768\n",
      "\n",
      "    accuracy                           0.60      6434\n",
      "   macro avg       0.59      0.48      0.49      6434\n",
      "weighted avg       0.60      0.60      0.58      6434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/p3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "model = LogisticRegression(solver='saga', multi_class=\"multinomial\",random_state=42).fit(X_train, y_train)\n",
    "\n",
    "#apply the model\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "# Model Accuracy, Precisiono and recall\n",
    "print(\"Confusion matrix:\\n\",metrics.confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Classification_report:\\n\",metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/leeo/Desktop/KI2/7.master_thesis/1.data/14.feature_label_intact_5min/label_fe/combine_fe/testing_data_binary.csv\"\n",
    "dftest = pd.read_csv(PATH, sep=\",\", header=0,\n",
    "                       parse_dates=[0], index_col=0)\n",
    "\n",
    "#add coefficient of variance\n",
    "df[\"cv\"] = df[\"std\"]/df[\"mean\"]\n",
    "df[\"cv.1\"] = df[\"std.1\"]/df[\"mean.1\"]\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-2:] + cols[:-2]\n",
    "df = df[cols]\n",
    "\n",
    "\n",
    "X_test=dftest[dftest.columns[:-2]]  # Features\n",
    "y_test=dftest[dftest.columns[-2]]  # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[22069  5081]\n",
      " [ 1847  2443]]\n",
      "Accuracy 0.7796437659033079\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.81      0.86     27150\n",
      "         1.0       0.32      0.57      0.41      4290\n",
      "\n",
      "    accuracy                           0.78     31440\n",
      "   macro avg       0.62      0.69      0.64     31440\n",
      "weighted avg       0.84      0.78      0.80     31440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RF\n",
    "#apply the model\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, Precisiono and recall\n",
    "print(\"Confusion matrix:\\n\",metrics.confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Classification_report:\\n\",metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/p3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/anaconda3/envs/p3/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:45:11] 30795x16 matrix with 492720 entries loaded from dtest.svm\n"
     ]
    }
   ],
   "source": [
    "# use DMatrix for xgbosot\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "\n",
    "# use svmlight file for xgboost\n",
    "dump_svmlight_file(X_test, y_test, 'dtest.svm', zero_based=True)\n",
    "dtest_svm = xgb.DMatrix('dtest.svm')\n",
    "\n",
    "# set xgboost params\n",
    "param = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this datset\n",
    "num_round = 10  # the number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[20444  5372   794]\n",
      " [ 1151  1283   119]\n",
      " [  394  1144    94]]\n",
      "Accuracy 0.708589056665043\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.77      0.84     26610\n",
      "         1.0       0.16      0.50      0.25      2553\n",
      "         2.0       0.09      0.06      0.07      1632\n",
      "\n",
      "    accuracy                           0.71     30795\n",
      "   macro avg       0.40      0.44      0.39     30795\n",
      "weighted avg       0.82      0.71      0.75     30795\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and testing - numpy matrices\n",
    "preds = bst.predict(dtest)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "#model evaluation: Model Accuracy, Precisiono and recall\n",
    "print(\"Confusion matrix:\\n\",metrics.confusion_matrix(y_test, best_preds))\n",
    "print(\"Accuracy\",metrics.accuracy_score(y_test, best_preds))\n",
    "print(\"Classification_report:\\n\",metrics.classification_report(y_test, best_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
